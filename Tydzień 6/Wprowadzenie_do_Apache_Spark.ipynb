{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wprowadzenie do Apache Spark.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-kv-ToZfwtEq"
      ],
      "authorship_tag": "ABX9TyMsyJ5L7HRDsx+OECnAj7lG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiotrMaciejKowalski/kurs-analiza-danych-2022/blob/main/Tydzie%C5%84%206/Wprowadzenie_do_Apache_Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Sparka\n",
        "\n",
        "## Utworzenie środowiska pyspark do obliczeń\n",
        "\n",
        "Tworzymy swoje środowisko z pysparkiem we wenętrzu naszych zasobów chmurowych"
      ],
      "metadata": {
        "id": "-kv-ToZfwtEq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K-Nw9adkwbsP"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q ftp.ps.pl/pub/apache/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "72SlZMkxya33"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "Y-DtnLhOydSI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "k2CRzSP0ygcu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark\n",
        "\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "oJCqLkLaylIX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utworzenie sesji z pyspark\n",
        "\n",
        "\n",
        "Utworzymy testowo sesję aby zobaczyć czy działa. Element ten jest wspólny również gdy systemy sparkowe pracują w sposób ciągły, a nie są tworzone przez naszą sesję."
      ],
      "metadata": {
        "id": "kIGkT1Zz4-Z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ],
      "metadata": {
        "id": "X_nydnCVy7X5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apache Spark \n",
        "\n",
        "**Apache Spark** to zunifikowany silnik do obliczeń rozproszonych na licencji open-source. Oferuje interfejs pozwalający na programowanie obliczeń na klastrach z domyślną paralelizacją oraz odpornością na awarie.\n",
        "\n",
        "Ze Sparkiem pracować można w Scali, Pythonie, Javie oraz R.\n",
        "\n",
        "Jego przewaga nad model Map-Reduce Hadoopa polega na unikaniu zapisów na hdfs tak długo jak to możliwe - i posługiwaniu się RAMem nodów jak długo go wystarcza.\n",
        "\n",
        "**Komponenty Sparka:**\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/PiotrMaciejKowalski/kurs-analiza-danych-2022/main/Tydzie%C5%84%206/cluster-overview.png\" alt=\"title\" width=\"500\"/>\n",
        "\n",
        "* Spark \"core\" - podstawa Sparka z podstawową abstrakcją danych nazywaną RDD\n",
        "* Spark SQL - komponent pozwalający na operowanie na ustrukturyzowanych danych z wykorzystaniem operacji znanych z SQL - łatwy w użyciu\n",
        "* Spark MLlib - komponent zawierający algorytmy ML dostępne w Sparku - ML na skalę klastrów\n",
        "* Spark Streaming - moduł pozwalający na pracę ze strumnieniami danych\n",
        "* Spark GraphX - komponent do pracy z grafami\n",
        "\n",
        "**Architektura Sparka:**\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/PiotrMaciejKowalski/kurs-analiza-danych-2022/main/Tydzie%C5%84%206/spark-stack.png\" alt=\"title\" width=\"500\"/>\n",
        "\n",
        "* driver - proces uruchamiający główną funkcję aplikacji i tworzący SparkContext\n",
        "* executor(y) - proces uruchomiony dla aplikacji w węźle roboczym (worker node), który uruchamia zadania i przechowuje dane w pamięci lub na dysku. Każda aplikacja ma własne executory\n",
        "* cluster manager - dostępne opcje: YARN, Mesos, Kubernetes, Standalone\n",
        "\n",
        "**SparkSession:**\n",
        "* wprowadzony w Spark 2.0\n",
        "* składa się ze SparkContextu, SQLContextu oraz HiveContext\n",
        "* zwykle nazywany w kodzie `spark`\n",
        "* kroki niezbędne do utworzenia SparkSession w pySparku:\n",
        "\n",
        "> from pyspark.sql import SparkSession  \n",
        "> spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "## RDD\n",
        "\n",
        "Podstawowym formatem danych (coś jak tabela w db) jest RDD. Skrót rozwija się następująco:\n",
        "* R - resilient (elastyczny)\n",
        "* D - distributed\n",
        "* D - dataset\n",
        "\n",
        "Model RDD jest napisany w sposób wspierający przekstrzałcenia Map-Reduce jako domyślny. W związku z powyższym wykazuje się następującymi własnościami:\n",
        "\n",
        "\n",
        "* immutable - każdy obiekt jest niezmienniczy. Chcesz coś zmienić - musisz utworzyć nowy rdd\n",
        "* in-memory - przetwarzany głównie w RAM\n",
        "* lazy evaluated - silnik obliczeniowy wykonuje obliczenia dopiero gdy okażą się konieczne.\n",
        "* parallel - współbieżny \n",
        "\n",
        "Z RDD stowarzyszone są dwa rodzaje czynności:\n",
        "* akcje, oraz\n",
        "* transformacje\n",
        "\n",
        "### Transformacje \n",
        "\n",
        "Modelują czynności jakie możemy chcieć wykonywać na danych. Przekształcenia (map), redukcje (reduce), filtry (filter). Mają charakter opisu skąd się biorą pewne wartości. W naszym ujęciu mogą odpowiadać funkcjom mapper, reducer i podobnym. \n",
        "\n",
        "_Dla osób, które kojarzą paradygmat funkcyjny programowania - można dodać, że transformacje dotyczą funkcji czystych._\n",
        "\n",
        "### Akcje\n",
        "\n",
        "Modelują czynności z uwagi na wynik jaki oczekujemy. Wyświetl, zapisz, wyszukaj. Mają charakter silnie połączony z wynikiem działania."
      ],
      "metadata": {
        "id": "WmcWNvu4HJTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aby obliczenia na danych zostały wykonane - musi zostać uruchomiona akcja. Dopiero ona wykona odpowiednie (i tylko te konieczne) transformacje.\n",
        "\n",
        "## DataFrame\n",
        "\n",
        "Choć RDD są wszędzie w Sparku, obecnie już się ich nie widzi. Od Sparka w wersji 2.0 zostały przesłonięte nowym interfejsem (zostały spakowane do wnętrza) czegoś nazywanego Ramką Danych (Dataframe). Skojarzenie z dataframe z R lub Pandas Python jest tutaj bardzo naturalne i prawdziwe. DataFrame Sparka były na nich wzorowane i pokrywają się w dużym obszarze składni.\n",
        "\n",
        "**DataFrame:**\n",
        "* abstrakcja danych z modułu Spark SQL\n",
        "* zawiera dodatkowe informacje o strukturze danych (schema)\n",
        "* pozwala na pracę z danymi wykorzysując zapytania znane z SQL/Hive\n",
        "\n",
        "Dalej zaprezentujemy jak to się odbywa w praktyce"
      ],
      "metadata": {
        "id": "XkyMB6tsHJbc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Podłączenie Google Drive do sesji colab"
      ],
      "metadata": {
        "id": "xHvcpXvTUHRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi4HFkt1UG59",
        "outputId": "dfd759c5-4d81-4d44-838e-06edd1189a92"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Przykładowy processing danych w Spark\n",
        "\n",
        "## Wczytanie danych do Sparka\n",
        "\n",
        "W tej części wczytamy sobie nasz plik `flights.csv` do przetwarzania w Spark.\n",
        "\n",
        "Z uwagi na to, że nasz plik to csv bez nagłówka - trzeba zdefiniować schemat dla danych, które przetwarzamy\n",
        "\n",
        "Przypomnijmy listę pól\n",
        "YEAR,MONTH,DAY,DAY_OF_WEEK,AIRLINE,FLIGHT_NUMBER,TAIL_NUMBER,ORIGIN_AIRPORT,\\\n",
        "DESTINATION_AIRPORT,SCHEDULED_DEPARTURE,DEPARTURE_TIME,DEPARTURE_DELAY,\\\n",
        "TAXI_OUT,WHEELS_OFF,SCHEDULED_TIME,ELAPSED_TIME,AIR_TIME,DISTANCE,WHEELS_ON,\\\n",
        "TAXI_IN,SCHEDULED_ARRIVAL,ARRIVAL_TIME,ARRIVAL_DELAY,DIVERTED,CANCELLED,\\\n",
        "CANCELLATION_REASON,AIR_SYSTEM_DELAY,SECURITY_DELAY,AIRLINE_DELAY,\\\n",
        "LATE_AIRCRAFT_DELAY,WEATHER_DELAY\n",
        "\n",
        "_Sporo ich. Więc najpierw trochę magii (bo nie chce mi się kodować każdego pola ręcznie, a jestem leniwy). Ufam, że przykład pozwoli rozszerzyć zastosowanie do bardziej skomplikowanych zastosowań. Na pocieszenie dodam, że wczytywanie csv bez nagłówka to najgorszy scenariusz w wersji wczytywania w sparku._"
      ],
      "metadata": {
        "id": "AOf1bVK0XK5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pola_zbiorczo = '''YEAR,MONTH,DAY,DAY_OF_WEEK,AIRLINE,FLIGHT_NUMBER,TAIL_NUMBER,ORIGIN_AIRPORT,DESTINATION_AIRPORT,SCHEDULED_DEPARTURE,DEPARTURE_TIME,DEPARTURE_DELAY,TAXI_OUT,WHEELS_OFF,SCHEDULED_TIME,ELAPSED_TIME,AIR_TIME,DISTANCE,WHEELS_ON,TAXI_IN,SCHEDULED_ARRIVAL,ARRIVAL_TIME,ARRIVAL_DELAY,DIVERTED,CANCELLED,CANCELLATION_REASON,AIR_SYSTEM_DELAY,SECURITY_DELAY,AIRLINE_DELAY,LATE_AIRCRAFT_DELAY,WEATHER_DELAY'''\n",
        "pola = pola_zbiorczo.split(',')"
      ],
      "metadata": {
        "id": "5q3upeS7Xdb7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A dalej użyjemy funkcji add(Nazwa, Typ pola, czy może być null) do zapisania prostego schematu danych"
      ],
      "metadata": {
        "id": "LcPWpEe2XgnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StringType\n",
        "\n",
        "schemat = StructType()\n",
        "for pole in pola:\n",
        "    schemat = schemat.add(pole, StringType(), True)"
      ],
      "metadata": {
        "id": "dqg20HMzXgFh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Przejdźmy do wczytywania"
      ],
      "metadata": {
        "id": "vYv4PqDnXldm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.format('csv').option(\"header\", False).schema(schemat).load('/content/drive/MyDrive/flights.csv')\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93HG9JboXkzr",
        "outputId": "a3ecaafb-a2f2-4bf0-88ce-0af10a351008"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
            "|YEAR|MONTH|DAY|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|CANCELLATION_REASON|AIR_SYSTEM_DELAY|SECURITY_DELAY|AIRLINE_DELAY|LATE_AIRCRAFT_DELAY|WEATHER_DELAY|\n",
            "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
            "|2015|    1|  1|          4|     AS|           98|     N407AS|           ANC|                SEA|               0005|          2354|            -11|      21|      0015|           205|         194|     169|    1448|     0404|      4|             0430|        0408|          -22|       0|        0|               null|            null|          null|         null|               null|         null|\n",
            "|2015|    1|  1|          4|     AA|         2336|     N3KUAA|           LAX|                PBI|               0010|          0002|             -8|      12|      0014|           280|         279|     263|    2330|     0737|      4|             0750|        0741|           -9|       0|        0|               null|            null|          null|         null|               null|         null|\n",
            "|2015|    1|  1|          4|     US|          840|     N171US|           SFO|                CLT|               0020|          0018|             -2|      16|      0034|           286|         293|     266|    2296|     0800|     11|             0806|        0811|            5|       0|        0|               null|            null|          null|         null|               null|         null|\n",
            "|2015|    1|  1|          4|     AA|          258|     N3HYAA|           LAX|                MIA|               0020|          0015|             -5|      15|      0030|           285|         281|     258|    2342|     0748|      8|             0805|        0756|           -9|       0|        0|               null|            null|          null|         null|               null|         null|\n",
            "|2015|    1|  1|          4|     AS|          135|     N527AS|           SEA|                ANC|               0025|          0024|             -1|      11|      0035|           235|         215|     199|    1448|     0254|      5|             0320|        0259|          -21|       0|        0|               null|            null|          null|         null|               null|         null|\n",
            "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Oi8_clWY3Dv",
        "outputId": "7ce11909-42c5-48bc-a7be-4660ba8fc9f7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['YEAR',\n",
              " 'MONTH',\n",
              " 'DAY',\n",
              " 'DAY_OF_WEEK',\n",
              " 'AIRLINE',\n",
              " 'FLIGHT_NUMBER',\n",
              " 'TAIL_NUMBER',\n",
              " 'ORIGIN_AIRPORT',\n",
              " 'DESTINATION_AIRPORT',\n",
              " 'SCHEDULED_DEPARTURE',\n",
              " 'DEPARTURE_TIME',\n",
              " 'DEPARTURE_DELAY',\n",
              " 'TAXI_OUT',\n",
              " 'WHEELS_OFF',\n",
              " 'SCHEDULED_TIME',\n",
              " 'ELAPSED_TIME',\n",
              " 'AIR_TIME',\n",
              " 'DISTANCE',\n",
              " 'WHEELS_ON',\n",
              " 'TAXI_IN',\n",
              " 'SCHEDULED_ARRIVAL',\n",
              " 'ARRIVAL_TIME',\n",
              " 'ARRIVAL_DELAY',\n",
              " 'DIVERTED',\n",
              " 'CANCELLED',\n",
              " 'CANCELLATION_REASON',\n",
              " 'AIR_SYSTEM_DELAY',\n",
              " 'SECURITY_DELAY',\n",
              " 'AIRLINE_DELAY',\n",
              " 'LATE_AIRCRAFT_DELAY',\n",
              " 'WEATHER_DELAY']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['YEAR','MONTH','DAY','AIRLINE','DISTANCE'].show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfAKsrWgUaXH",
        "outputId": "f2e82d90-5bed-4fff-ada6-74f262018e22"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+---+-------+--------+\n",
            "|YEAR|MONTH|DAY|AIRLINE|DISTANCE|\n",
            "+----+-----+---+-------+--------+\n",
            "|2015|    1|  1|     AS|    1448|\n",
            "|2015|    1|  1|     AA|    2330|\n",
            "|2015|    1|  1|     US|    2296|\n",
            "|2015|    1|  1|     AA|    2342|\n",
            "|2015|    1|  1|     AS|    1448|\n",
            "|2015|    1|  1|     DL|    1589|\n",
            "|2015|    1|  1|     NK|    1299|\n",
            "|2015|    1|  1|     US|    2125|\n",
            "|2015|    1|  1|     AA|    1464|\n",
            "|2015|    1|  1|     DL|    1747|\n",
            "|2015|    1|  1|     DL|    1199|\n",
            "|2015|    1|  1|     AA|    2174|\n",
            "|2015|    1|  1|     DL|    1535|\n",
            "|2015|    1|  1|     DL|    1590|\n",
            "|2015|    1|  1|     DL|    1399|\n",
            "|2015|    1|  1|     AS|    1448|\n",
            "|2015|    1|  1|     DL|    1448|\n",
            "|2015|    1|  1|     UA|    1635|\n",
            "|2015|    1|  1|     AS|    1542|\n",
            "|2015|    1|  1|     DL|    1426|\n",
            "+----+-----+---+-------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUCjh98hY7E2",
        "outputId": "fd191c2c-7cc3-4a78-afdb-794832c82af4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- YEAR: string (nullable = true)\n",
            " |-- MONTH: string (nullable = true)\n",
            " |-- DAY: string (nullable = true)\n",
            " |-- DAY_OF_WEEK: string (nullable = true)\n",
            " |-- AIRLINE: string (nullable = true)\n",
            " |-- FLIGHT_NUMBER: string (nullable = true)\n",
            " |-- TAIL_NUMBER: string (nullable = true)\n",
            " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
            " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
            " |-- SCHEDULED_DEPARTURE: string (nullable = true)\n",
            " |-- DEPARTURE_TIME: string (nullable = true)\n",
            " |-- DEPARTURE_DELAY: string (nullable = true)\n",
            " |-- TAXI_OUT: string (nullable = true)\n",
            " |-- WHEELS_OFF: string (nullable = true)\n",
            " |-- SCHEDULED_TIME: string (nullable = true)\n",
            " |-- ELAPSED_TIME: string (nullable = true)\n",
            " |-- AIR_TIME: string (nullable = true)\n",
            " |-- DISTANCE: string (nullable = true)\n",
            " |-- WHEELS_ON: string (nullable = true)\n",
            " |-- TAXI_IN: string (nullable = true)\n",
            " |-- SCHEDULED_ARRIVAL: string (nullable = true)\n",
            " |-- ARRIVAL_TIME: string (nullable = true)\n",
            " |-- ARRIVAL_DELAY: string (nullable = true)\n",
            " |-- DIVERTED: string (nullable = true)\n",
            " |-- CANCELLED: string (nullable = true)\n",
            " |-- CANCELLATION_REASON: string (nullable = true)\n",
            " |-- AIR_SYSTEM_DELAY: string (nullable = true)\n",
            " |-- SECURITY_DELAY: string (nullable = true)\n",
            " |-- AIRLINE_DELAY: string (nullable = true)\n",
            " |-- LATE_AIRCRAFT_DELAY: string (nullable = true)\n",
            " |-- WEATHER_DELAY: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa2lKAeQY9fH",
        "outputId": "8f23112b-7cf5-4429-9d59-88cf342ac7c6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 44.9 ms, sys: 5.9 ms, total: 50.8 ms\n",
            "Wall time: 5.66 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5819079"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zapytania Spark-SQL\n",
        "\n",
        "Zapytania do Sparka kierowane są za pomocą \n",
        "\n",
        "* składni a.k.a. SQL, lub\n",
        "* wyrażone w ORM (object relational mapping) czyli obiektowym sposobie na wyrażanie kwerend.\n",
        "\n",
        "Składniowo wydaje się, że zapytania SQL są łatwiejsze do zapisania. W kilku przypadkach jednak jawne zadanie kolejności obliczeń może pomóc zoptymalizować kształt zapytania.\n",
        "\n",
        "Zaprezentuje kilka podstawowych sposób na odpytywanie Spark DataFrame kwerendami o różnych naturach. Zawsze podane obe będą w postaci SparkSQL oraz wyrażenia ORM.\n",
        "\n",
        "### Proste kwerendy\n",
        "\n",
        "Zanim zacznimy pisać kwerendy należy jeszcze dodać nasz DataFrame do 'przestrzeni nazw tabel' Sparka. Formalnie nazywane jest to widokiem danych "
      ],
      "metadata": {
        "id": "0WSmiUSyZPTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"df\")"
      ],
      "metadata": {
        "id": "nZG8gmcPY_D7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wykonajmy prostego Selecta z tego zbioru.\n",
        "\n",
        "Przypominam, że do uruchomienia sparka potrzebna jest akcja. Np. taki `show()`"
      ],
      "metadata": {
        "id": "eJ4RB7KbZd32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('select airline, distance from df').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy0PQJBCZZow",
        "outputId": "01163972-0214-4939-c216-16a622e1361b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+\n",
            "|airline|distance|\n",
            "+-------+--------+\n",
            "|     AS|    1448|\n",
            "|     AA|    2330|\n",
            "|     US|    2296|\n",
            "|     AA|    2342|\n",
            "|     AS|    1448|\n",
            "|     DL|    1589|\n",
            "|     NK|    1299|\n",
            "|     US|    2125|\n",
            "|     AA|    1464|\n",
            "|     DL|    1747|\n",
            "|     DL|    1199|\n",
            "|     AA|    2174|\n",
            "|     DL|    1535|\n",
            "|     DL|    1590|\n",
            "|     DL|    1399|\n",
            "|     AS|    1448|\n",
            "|     DL|    1448|\n",
            "|     UA|    1635|\n",
            "|     AS|    1542|\n",
            "|     DL|    1426|\n",
            "+-------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select('airline','distance').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q510rgbZcr8",
        "outputId": "e5da5c94-0ae0-4976-8439-d6eafadd579d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+\n",
            "|airline|distance|\n",
            "+-------+--------+\n",
            "|     AS|    1448|\n",
            "|     AA|    2330|\n",
            "|     US|    2296|\n",
            "|     AA|    2342|\n",
            "|     AS|    1448|\n",
            "|     DL|    1589|\n",
            "|     NK|    1299|\n",
            "|     US|    2125|\n",
            "|     AA|    1464|\n",
            "|     DL|    1747|\n",
            "|     DL|    1199|\n",
            "|     AA|    2174|\n",
            "|     DL|    1535|\n",
            "|     DL|    1590|\n",
            "|     DL|    1399|\n",
            "|     AS|    1448|\n",
            "|     DL|    1448|\n",
            "|     UA|    1635|\n",
            "|     AS|    1542|\n",
            "|     DL|    1426|\n",
            "+-------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sprawniejsze wyświetlanie danych sparkowych"
      ],
      "metadata": {
        "id": "bsZ7C6s_dVng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select('airline','distance').toPandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tMqrI4GJZjnK",
        "outputId": "c4b691da-6ede-4871-f378-91e91f56fee5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        airline distance\n",
              "0            AS     1448\n",
              "1            AA     2330\n",
              "2            US     2296\n",
              "3            AA     2342\n",
              "4            AS     1448\n",
              "...         ...      ...\n",
              "5819074      B6     2611\n",
              "5819075      B6     1617\n",
              "5819076      B6     1598\n",
              "5819077      B6     1189\n",
              "5819078      B6     1576\n",
              "\n",
              "[5819079 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57aa25df-1c37-4a27-aea8-f69dcb16fdc2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline</th>\n",
              "      <th>distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AS</td>\n",
              "      <td>1448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AA</td>\n",
              "      <td>2330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US</td>\n",
              "      <td>2296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AA</td>\n",
              "      <td>2342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AS</td>\n",
              "      <td>1448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5819074</th>\n",
              "      <td>B6</td>\n",
              "      <td>2611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5819075</th>\n",
              "      <td>B6</td>\n",
              "      <td>1617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5819076</th>\n",
              "      <td>B6</td>\n",
              "      <td>1598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5819077</th>\n",
              "      <td>B6</td>\n",
              "      <td>1189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5819078</th>\n",
              "      <td>B6</td>\n",
              "      <td>1576</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5819079 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57aa25df-1c37-4a27-aea8-f69dcb16fdc2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57aa25df-1c37-4a27-aea8-f69dcb16fdc2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57aa25df-1c37-4a27-aea8-f69dcb16fdc2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proste grupowania i agregacje\n",
        "\n",
        "Dalej proste pogrupowanie z polem poddanym agregacji."
      ],
      "metadata": {
        "id": "Jq8kWjoGdVr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "spark.sql('select airline, count(*) as count from df group by airline').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3ua5JxOeOt8",
        "outputId": "368a875e-7df5-4ced-e9a6-1eade19f99ce"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+\n",
            "|airline|  count|\n",
            "+-------+-------+\n",
            "|     UA| 515723|\n",
            "|     NK| 117379|\n",
            "|     AA| 725984|\n",
            "|     EV| 571977|\n",
            "|     B6| 267048|\n",
            "|     DL| 875881|\n",
            "|     OO| 588353|\n",
            "|     F9|  90836|\n",
            "|     US| 198715|\n",
            "|     MQ| 294632|\n",
            "|     HA|  76272|\n",
            "|     AS| 172521|\n",
            "|     VX|  61903|\n",
            "|     WN|1261855|\n",
            "+-------+-------+\n",
            "\n",
            "CPU times: user 96.8 ms, sys: 8.17 ms, total: 105 ms\n",
            "Wall time: 14.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "df.groupBy('airline').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foC3X34WeQBC",
        "outputId": "0c40d2b2-2ae7-41b6-fed5-ccf66ad10124"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+\n",
            "|airline|  count|\n",
            "+-------+-------+\n",
            "|     UA| 515723|\n",
            "|     NK| 117379|\n",
            "|     AA| 725984|\n",
            "|     EV| 571977|\n",
            "|     B6| 267048|\n",
            "|     DL| 875881|\n",
            "|     OO| 588353|\n",
            "|     F9|  90836|\n",
            "|     US| 198715|\n",
            "|     MQ| 294632|\n",
            "|     HA|  76272|\n",
            "|     AS| 172521|\n",
            "|     VX|  61903|\n",
            "|     WN|1261855|\n",
            "+-------+-------+\n",
            "\n",
            "CPU times: user 92.4 ms, sys: 8.72 ms, total: 101 ms\n",
            "Wall time: 13.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Klauzala sortująca\n",
        "\n",
        "Możemy dane uporządkować względem kolumny"
      ],
      "metadata": {
        "id": "Vd6DdvwoeT2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "spark.sql('select airline, count(*) as count from df group by airline order by count').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXRVONlQeRlz",
        "outputId": "412ba233-7ae3-48f9-ee37-b985a4ba7ee2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+\n",
            "|airline|  count|\n",
            "+-------+-------+\n",
            "|     VX|  61903|\n",
            "|     HA|  76272|\n",
            "|     F9|  90836|\n",
            "|     NK| 117379|\n",
            "|     AS| 172521|\n",
            "|     US| 198715|\n",
            "|     B6| 267048|\n",
            "|     MQ| 294632|\n",
            "|     UA| 515723|\n",
            "|     EV| 571977|\n",
            "|     OO| 588353|\n",
            "|     AA| 725984|\n",
            "|     DL| 875881|\n",
            "|     WN|1261855|\n",
            "+-------+-------+\n",
            "\n",
            "CPU times: user 91.8 ms, sys: 8.66 ms, total: 100 ms\n",
            "Wall time: 13.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "df.groupBy('airline').count().orderBy('count').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0WKisQQea72",
        "outputId": "bb99cbba-ecfc-47a8-d820-5fe155278e3e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+\n",
            "|airline|  count|\n",
            "+-------+-------+\n",
            "|     VX|  61903|\n",
            "|     HA|  76272|\n",
            "|     F9|  90836|\n",
            "|     NK| 117379|\n",
            "|     AS| 172521|\n",
            "|     US| 198715|\n",
            "|     B6| 267048|\n",
            "|     MQ| 294632|\n",
            "|     UA| 515723|\n",
            "|     EV| 571977|\n",
            "|     OO| 588353|\n",
            "|     AA| 725984|\n",
            "|     DL| 875881|\n",
            "|     WN|1261855|\n",
            "+-------+-------+\n",
            "\n",
            "CPU times: user 89.5 ms, sys: 9.54 ms, total: 99 ms\n",
            "Wall time: 13 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Możemy zmienić funkcje agregacji na mniej oczywistą lub zadać ich więcej.\n"
      ],
      "metadata": {
        "id": "Wq5RPs9WeghP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "spark.sql('select airline, max(distance) as maks, min(distance) as min from df group by airline').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yubp7LvMeeHa",
        "outputId": "9a9d0872-ee74-461a-e5e9-2393520ac928"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+----+\n",
            "|airline|maks| min|\n",
            "+-------+----+----+\n",
            "|     UA| 997| 100|\n",
            "|     NK| 986|1005|\n",
            "|     AA| 993|1005|\n",
            "|     EV| 999| 100|\n",
            "|     B6| 997|1005|\n",
            "|     DL| 991|1005|\n",
            "|     OO| 996|1004|\n",
            "|     F9| 993|1005|\n",
            "|     US| 993|1009|\n",
            "|     MQ| 999|1013|\n",
            "|     HA|  84| 100|\n",
            "|     AS| 987|1009|\n",
            "|     VX| 954|1067|\n",
            "|     WN| 999|1005|\n",
            "+-------+----+----+\n",
            "\n",
            "CPU times: user 120 ms, sys: 8.09 ms, total: 128 ms\n",
            "Wall time: 18.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "from pyspark.sql import functions as sf #spark functions\n",
        "\n",
        "df.groupBy('airline').agg(sf.max('distance').alias('maks'), sf.min('distance').alias('min')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exmGTe-helnb",
        "outputId": "f77ed130-ca53-4595-cc52-91ddac6de3e9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+----+\n",
            "|airline|maks| min|\n",
            "+-------+----+----+\n",
            "|     UA| 997| 100|\n",
            "|     NK| 986|1005|\n",
            "|     AA| 993|1005|\n",
            "|     EV| 999| 100|\n",
            "|     B6| 997|1005|\n",
            "|     DL| 991|1005|\n",
            "|     OO| 996|1004|\n",
            "|     F9| 993|1005|\n",
            "|     US| 993|1009|\n",
            "|     MQ| 999|1013|\n",
            "|     HA|  84| 100|\n",
            "|     AS| 987|1009|\n",
            "|     VX| 954|1067|\n",
            "|     WN| 999|1005|\n",
            "+-------+----+----+\n",
            "\n",
            "CPU times: user 118 ms, sys: 15.7 ms, total: 133 ms\n",
            "Wall time: 16.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtrowanie danych\n",
        "\n",
        "Bardzo ważne jest oczywiście odflitrowanie części dużego zbioru danych. \n",
        "\n",
        "_Uwaga pamiętajmy, że leniwie wczytując plik skazałem wszystkie pola na bycie Stringami._"
      ],
      "metadata": {
        "id": "wTtH38jDerZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "spark.sql('select airline, count(*) as count from df  where day_of_week = \"2\" group by airline').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRSu3X7deoJD",
        "outputId": "0c85d3c1-4ee5-4702-a2ec-6758cacd631b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+\n",
            "|airline| count|\n",
            "+-------+------+\n",
            "|     UA| 74945|\n",
            "|     NK| 16359|\n",
            "|     AA|103401|\n",
            "|     EV| 83541|\n",
            "|     B6| 37753|\n",
            "|     DL|128412|\n",
            "|     OO| 84054|\n",
            "|     F9| 12991|\n",
            "|     US| 28496|\n",
            "|     MQ| 42970|\n",
            "|     HA| 10516|\n",
            "|     AS| 24165|\n",
            "|     VX|  8990|\n",
            "|     WN|188007|\n",
            "+-------+------+\n",
            "\n",
            "CPU times: user 80 ms, sys: 5.44 ms, total: 85.4 ms\n",
            "Wall time: 11.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df.where('day_of_week = \"2\"').groupBy('airline').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRbjUi9weuYf",
        "outputId": "24c84a7e-ae58-431b-eb3e-6ff24c6decb1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+\n",
            "|airline| count|\n",
            "+-------+------+\n",
            "|     UA| 74945|\n",
            "|     NK| 16359|\n",
            "|     AA|103401|\n",
            "|     EV| 83541|\n",
            "|     B6| 37753|\n",
            "|     DL|128412|\n",
            "|     OO| 84054|\n",
            "|     F9| 12991|\n",
            "|     US| 28496|\n",
            "|     MQ| 42970|\n",
            "|     HA| 10516|\n",
            "|     AS| 24165|\n",
            "|     VX|  8990|\n",
            "|     WN|188007|\n",
            "+-------+------+\n",
            "\n",
            "CPU times: user 78.1 ms, sys: 7.01 ms, total: 85.1 ms\n",
            "Wall time: 11.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zaawansowany preprocessing danych w Spark"
      ],
      "metadata": {
        "id": "xo581pEdh_du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rf4cVyFdiZmE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}